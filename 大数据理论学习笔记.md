#  大数据理论学习笔记

## 大数据的技术特点

* Volume(大体量)
* Variety(多样性)

大数据包括各种格式和形态的数据

* Velocity(时效性)

很多大数据需要保证在一定的时间限度下得到及时处理。

* Veracity(准确性)

  处理的结果要保证一定的准确性

* Value(大价值)

大数据包含很多深度的价值，大数据分析挖掘和利用将带来巨大的商业价值。

## 大数据的类型与计算特征

- [ ] 从数据结构特征的角度看

      大数据可分为结构化、非结构化、半结构化数据

- [ ] 从数据获取处理方式来看


​         大数据可分为批处理与流式计算方式 

- [ ] 从数据处理类型来看

      大数据可分为传统的查询分析计算和复杂数据挖掘计算

- [ ] 从大数据处理响应来看

      可分为实时/准实时与非实时计算。或者是联机计算与线下计算。

- [ ] 从数据关系来看

      可分为简单关系数据（如web日志)和复杂关系数据(如社会网络等具有复杂数据关系的图计算)

- [ ] 从迭代计算角度来看

- [ ] 从并行计算体系结构特征来看

      集群的分布式存储、与并行计算体系结构和硬件平台。 内存计算。

## 大数据研究的主要目标、基本原则和基本途径

1. 主要目标

   以有效的信息技术手段和计算方法，获取、处理和分析各种应用行业的大数据，发现和提取数据的深度价值，为行业提供高附加值的应用和服务。因此，大数据研究的核心目标是价值发现，而其技术手段是信息技术和计算方法，其效益目标是为行业提供高附加值的应用和服务。

2. 基本特点

   1）具有很强的行业应用需求特性，因此大数据技术研究必须紧扣行业应用需求

   2）大数据规模极大，超过任何传统数据库的处理能力

   3）处理技术综合性强，任何单一层面的计算技术都能以提供理想的解决方案，需要采用综合性的软硬件技术才能有效处理

   4）大数据处理时，大多传统算法都面临失效，需要重写。

3. 基本原则

   1）应用需求为导向：从行业实际的应用需求和存在的技术难题入手，研究解决有效的处理技术和解决方案。

   2）领域交叉为桥梁：大数据技术研究和应用开发需要开发人员、数据分析师、具备专业知识的领域专家相互配合和协同，促进应用行业、IT产业与计算技术研究机构的交叉融合，来提供良好的大数据解决方法。

   3)技术综合为支撑

4. 基本途径

   1）寻找新算法降低计算复杂度。

   2）寻找和采用降低数据尺度的算法。在保证结果精度的前提下，用数据抽样或者数据尺度无关的近似算法来完成大数据的处理

   3）分而治之的并行化处理。

## 大数据计算模式和系统

 　　大数据计算模式，是指根据大数据的不同数据特征和计算特征，从多样性的大数据计算问题和需求中提炼并建立的各种高层抽象（Ａbstraction)和模型（Model)。传统的并行计算方法主要从体系结构和编程语言的层面定义了一些较为底层的抽象和模型。但由于大数据处理问题具有很多高层的数据特征和计算特征，因此大数据处理需要更多地结合其数据特征和计算特性考虑更为更为高层的计算模式。

![bigdatasystool](images/bigdatasystool.png)



![bigdatasystemwide](images/bigdatasystemwide.png)



## 大数据计算框架底层需要自动完成的处理：

(1)计算任务的自动划分和调度。

(2)数据的自动化分布存储或划分

(3)处理数据与计算任务的同步

(4)结果数据的收集整理(sorting,combining,partitioning,等)

(5)系统通信、负载平衡、计算性能优化处理

(6)处理系统节点出错检测和失效恢复

## Hadoop分布式存储与并行计算框架



![Hadoop分布式存储与并行计算框架](images/Hadoop分布式存储与并行计算框架.png)

## Hadoop平台基本组成与生态系统

![Hadoop平台的基本组成与生态系统](images/Hadoop平台的基本组成与生态系统.png)





## 搭建hadoop集群环境

### 系统环境准备

**创建用户组及用户**

```sh
groupadd -g 10000 bigdata
useradd -m -g bigdata -u 10000 bigdata
passwd bigdata
```

**安装jdk7**

```sh
tar -C /opt/java -xf jdk-7u80-linux-x64
```

**配置Java环境变量(/home/bigdata/.bashrc)**

```sh
JAVA_HOME=/opt/java/jdk1.7.0_80
PATH=${JAVA_HOME}/bin:$PATH
CLASSPATH=.:${JAVA_HOME}/lib/dt.jar:${JAVA_HOME}/lib/tools.jar
export JAVA_HOME
export PATH
export CLASSPATH
HADOOP_HOME=/opt/hadoop/hadoop-2.6.0
export HADOOP_HOME
```

```sh
#创建/opt/hadoop目录，所有者为bigdata
sudo mkdir -p /opt/hadoop
sudo chown -R bigdata:bigdata /opt/hadoop
```



**配置ssh无密码登录**

1. 设置hosts文件。在/etc/hosts/文件中配置IP与HOSTNAME的映射

```sh
192.168.56.101  centos71 master
192.168.56.102  centos72 slave1
192.168.56.103  centos73 slave2
192.168.56.104  centos74 slave3
```

2. 生成公钥和私钥，执行ssh-keygen -t rsa,接着连续按3次回车键

```sh
ssh-keygen  -t rsa
```

​	接着分别执行：

```sh
ssh-copy-id -i /home/bigdata/.ssh/id_rsa.pub bigdata@master
ssh-copy-id -i /home/bigdata/.ssh/id_rsa.pub bigdata@slave1
ssh-copy-id -i /home/bigdata/.ssh/id_rsa.pub bigdata@slave2
ssh-copy-id -i /home/bigdata/.ssh/id_rsa.pub bigdata@slave3
```

​	接着验证无密码登录是否配置成功：

```sh
ssh master
ssh slave1
ssh slave2
ssh slave3
```

**安装配置NTP**

```sh
#安装ntp，配置开机自启动，当前启动ntpd
sudo yum install -y ntp
sudo systemctl enable ntpd
sudo systemctl start ntpd
sudo ntpdate -u cn.pool.ntp.org


```

​    配置/etc/ntp.conf

下面在master上配置（当作ntp server服务器）

```sh
#在#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap后增加下行
restrict 192.168.56.0 mask 255.255.255.0 nomodify notrap
#注释server 0.centos.pool.ntp.org iburst\nserver 1.centos.pool.ntp.org iburst\nserver 2.centos.pool.ntp.org iburst \nserver 3.centos.pool.ntp.org iburst
#增加下列三行
server 2.cn.pool.ntp.org
server 1.asia.pool.ntp.org
server 2.asia.pool.ntp.org
server 127.127.1.0  # local clock
fudge 127.127.1.0  stratum 10
#在# Enable public key cryptography.
restrict 2.cn.pool.ntp.org nomodify notrap noquery
restrict 1.asia.pool.ntp.org nomodify notrap noquery
restrict 2.asia.pool.ntp.org nomodify notrap noquery

```

下面在slave1,slave2,slave3上配置

```sh
#把# Please consider joining the pool 下面server开头的几行注释掉
#增加master作为ntp本地服务器
#配置上游时间服务器为本地的ntpd Server服务器
server master
# 配置允许上游时间服务器主动修改本机的时间
server master
server 127.127.1.0
fudge 127.127.1.0  stratum 10
```



### 配置Hadoop集群

上转Hadoop安装包到master机器，并解压到/opt/hadoop/

涉及的配置文件有：

```sh
${HADOOP_HOME}/etc/hadoop/hadoop-env.sh
${HADOOP_HOME}/etc/hadoop/yarn-env.sh
${HADOOP_HOME}/etc/hadoop/slaves
${HADOOP_HOME}/etc/hadoop/core-site.xml
${HADOOP_HOME}/etc/hadoop/hdfs-site.xml
${HADOOP_HOME}/etc/hadoop/mapred-site.xml
${HADOOP_HOME}/etc/hadoop/yarn-site.xml
```

1)配置文件1:hadoop-env.sh

```sh
export JAVA_HOME=${JAVA_HOME} #如果用户的环境变量未设置或版本不对，可调整此参数
```

2）配置文件2：yarn-env.sh

```sh
#如果用户的环境变量未设置或版本不对，可调整此参数
```

3）配置文件3:slaves

```sh
slave1
slave2
slave3
```

4)配置文件4：core-site.xml

需先执行下列命令：

sudo mkdir -p /var/log/hadoop/tmp

sudo chown -R bigdata:bigdata /var/log/hadoop



```sh
<configuration>
   <property>
             <name>fs.defaultFS</name>
             <value>hdfs://master:8020</value>
  </property>
  <property>
            <name>hadoop.tmp.dir</name>
            <value>/var/log/hadoop/tmp</value>
  </property>
</configuration>
```

5)配置文件5：hdfs-site.xml

需先执行下列命令：

sudo mkdir -p /data/hadoop/hdfs/name

sudo mkdir  -p  /data/hadoop/hdfs/data

sudo chown -R bigdata:bigdata /data



```sh
<configuration>
    <property>
     <name>dfs.namenode.name.dir</name>
     <value>file:///data/hadoop/hdfs/name</value>
   </property>
   <property>
        <name>dfs.datanode.data.dir</name>
       <value>file:///data/hadoop/hdfs/data</value>
   </property>
   <property>
              <name>dfs.namenode.secondary.http-address</name>
              <value>master:50090</value>
  </property>
   <property>
          <name>dfs.replication</name>
          <value>3</value>
  </property>

</configuration>
```

6)配置文件6：mapred-site.xml

```sh
cp mapred-site.xml.template  mapred-site.xml
```

```sh
<configuration>
   <property>
   <name>mapreduce.framework.name</name>
   <value>yarn</value>
  </property>
  <property>
          <name>mapreduce.jobhistory.address</name>
          <value>master:10020</value>
  </property>
  <property>
           <name>mapreduce.jobhistory.webapp.address</name>
           <value>master:19888</value>
  </property>

</configuration>
```

7)配置文件7:yarn-site.xml

```sh
sudo mkdir -p /data/hadoop/yarn/local
sudo mkdir -p /data/tmp/logs
sudo chown -R bigdata:bigdata /data/hadoop/yarn/local
sudo chown -R bigdata:bigdata /data/tmp
```

```xml
<?xml version="1.0"?>
<configuration>
  <property>
    <description>The hostname of the RM.</description>
    <name>yarn.resourcemanager.hostname</name>
    <value>master</value>
  </property>
  <property>
    <name>yarn.resourcemanager.address</name>
    <value>${yarn.resourcemanager.hostname}:8032</value>
  </property>
  <property>
    <name>yarn.resourcemanager.scheduler.address</name>
    <value>${yarn.resourcemanager.hostname}:8030</value>
  </property>
  <property>
    <name>yarn.resourcemanager.webapp.address</name>
    <value>${yarn.resourcemanager.hostname}:8088</value>
  </property>
  <property>
    <name>yarn.resourcemanager.webapp.https.address</name>
    <value>${yarn.resourcemanager.hostname}:8090</value>
  </property>
  <property>
    <name>yarn.resourcemanager.resource-tracker.address</name>
    <value>${yarn.resourcemanager.hostname}:8031</value>
  </property>
  <property>
    <name>yarn.resourcemanager.admin.address</name>
    <value>${yarn.resourcemanager.hostname}:8033</value>
  </property>
  <property>
    <name>yarn.nodemanager.local-dirs</name>
    <value>/data/hadoop/yarn/local</value>
  </property>
  <property>
    <name>yarn.log-aggregation-enable</name>
    <value>true</value>
  </property>
   <property>
    <name>yarn.nodemanager.remote-app-log-dir</name>
    <value>/data/tmp/logs</value>
  </property>
  <property>
  <name>yarn.log.server.url</name>
  <value>http://master:19888/jobhistory/logs/</value>
 </property>
 <property>
  <name>yarn.nodemanager.vmem-check-enabled</name>
 <value>false</value>
 </property>
 <property>
 <name>yarn.nodemanager.aux-services</name>
 <value>mapreduce_shuffle</value>
 </property>
<property>
<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
<value>org.apache.hadoop.mapred.ShuffleHandler</value>
</property>
</configuration>
```

### 复制程序到其它节点

```sh
 scp -r /opt/hadoop/hadoop-2.6.0/ slave1:/opt/hadoop
 scp -r /opt/hadoop/hadoop-2.6.0/ slave2:/opt/hadoop
 scp -r /opt/hadoop/hadoop-2.6.0/ slave3:/opt/hadoop
```

### 格式化NameNode

```sh
${HADOOP_HOME}/bin/hdfs namenode -format
```

### 集群启动关闭与监控

​	启动集群，只要在master节点（NameNode服务所在节点）执行下列命令

**启动集群**

```sh
cd $HADOOP_HOME
sbin/start-dfs.sh
sbin/start-yarn.sh
sbin/mr-jobhistory-daemon.sh start historyserver
```

**关闭集群**

```sh
cd $HADOOP_HOME
sbin/stop-yarn.sh
sbin/stop-dfs.sh
sbin/mr-jobhistory-daemon.sh stop historyserver
```

**查看集群状态**

```sh
bin/hdfs dfsadmin -report
```

**hadoop集群监控相关端口**

| 服务                          | Web接口                              | 默认端口  |
| --------------------------- | ---------------------------------- | ----- |
| NameNode                    | http://namenode_host:port/         | 50070 |
| ResourceManager             | http://resourcemanager_host:port/  | 8088  |
| MapReduce JobHistory Server | http://jobhistoryserver_host:port/ | 19888 |



yarn jar /opt/hadoop/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar wordcount /home/bigdata/abc/test.sh /home/bigdata/abc/wc_00